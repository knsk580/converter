{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07af779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install lxml\n",
    "!pip install requests\n",
    "!pip install langchain\n",
    "!pip install langchain-text-splitters\n",
    "!pip install tiktoken\n",
    "!pip install docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae776842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "# ファイルをアップロードさせる\n",
    "uploaded_files = files.upload()\n",
    "\n",
    "for file_name in uploaded_files.keys():\n",
    "    print(f\"Processing... {file_name}\")\n",
    "    file_contents = uploaded_files[file_name]\n",
    "\n",
    "    # HTMLの不要タグを除去\n",
    "    soup = BeautifulSoup(file_contents, \"html.parser\")\n",
    "    [element.decompose() for element in soup.find_all(\"script\")]\n",
    "    # [element.decompose() for element in soup.find_all(\"a\", attrs={\"class\": \"link\"})]\n",
    "    # [element.decompose() for element in soup.find_all(\"img\", attrs={\"src\": re.compile(\".*\\.png$\")})]\n",
    "    souped_content = str(soup)\n",
    "\n",
    "    # 正規表現によるテキスト除去\n",
    "    cleaned_content = re.sub(\"<footer.*?>.*?</footer>\", '', souped_content, flags=re.MULTILINE | re.DOTALL)\n",
    "\n",
    "    # マークダウンに変換\n",
    "    document_converter = DocumentConverter()\n",
    "    covert_result = document_converter.convert_string(content=cleaned_content, format=InputFormat.HTML, name=file_name)\n",
    "    markdown = covert_result.document.export_to_markdown()\n",
    "\n",
    "    # マークダウンファイルを保存\n",
    "    markdown_file_path = Path(file_name).stem + \".md\"\n",
    "    with open(markdown_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(markdown)\n",
    "\n",
    "    # マークダウンをJSONに変換する\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header1\"),\n",
    "        (\"##\", \"Header2\"),\n",
    "        (\"###\", \"Header3\"),\n",
    "        (\"####\", \"Header4\"),\n",
    "    ]\n",
    "    splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=headers_to_split_on,\n",
    "        strip_headers=True,\n",
    "        return_each_line=False,\n",
    "    )\n",
    "    splitted_docs = splitter.split_text(markdown)\n",
    "    splitted_jsons = []\n",
    "    for i, doc in enumerate(splitted_docs):\n",
    "        splitted_json = {\n",
    "#            \"id\": f\"{file_name}_{i}\",\n",
    "            \"content\": doc.page_content.strip(),\n",
    "            \"metadata\": {\n",
    "                **doc.metadata\n",
    "            }\n",
    "        }\n",
    "        splitted_jsons.append(splitted_json)\n",
    "\n",
    "    # JSONファイルを保存\n",
    "    json_file_path = Path(file_name).stem + \".json\"\n",
    "    with open(json_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(splitted_jsons, f, ensure_ascii=False, indent=2)\n",
    "    # 完了を知らせるログを出力する\n",
    "    print(f\"{file_name} の変換が完了しました。\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
